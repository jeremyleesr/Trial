<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<title>Piano Pitch Test</title>

<style>
body {
    margin: 0;
    background: #111;
    color: white;
    font-family: Arial, sans-serif;
}
#container {
    display: flex;
    flex-direction: column;
    align-items: center;
    justify-content: center;
    min-height: 100vh;
}
canvas {
    background: #222;
    border: 2px solid #555;
}
button {
    font-size: 26px;
    padding: 16px 36px;
    margin-top: 20px;
    border-radius: 10px;
    border: none;
    background: #4CAF50;
    color: white;
    font-weight: bold;
}
</style>
</head>

<body>
<div id="container">
    <canvas id="gameCanvas" width="800" height="300"></canvas>
    <button id="startButton">Start</button>
</div>

<script>
const canvas = document.getElementById("gameCanvas");
const ctx = canvas.getContext("2d");
const startButton = document.getElementById("startButton");

const NOTE_NAMES = ["C","C#","D","D#","E","F","F#","G","G#","A","A#","B"];

function frequencyToNote(freq) {
    const A4 = 440;
    const midi = Math.round(12 * Math.log2(freq / A4) + 69);
    return NOTE_NAMES[midi % 12] + (Math.floor(midi / 12) - 1);
}

let audioContext;
let pitchNode;
let currentPitch = 0;
let currentNote = null;

async function startAudio() {
    startButton.textContent = "Initializing…";
    startButton.disabled = true;

    try {
        audioContext = new (window.AudioContext || window.webkitAudioContext)();
        await audioContext.resume();

        // IMPORTANT: relative path for GitHub Pages project repo
        await audioContext.audioWorklet.addModule("./pitch-processor.js");

        const stream = await navigator.mediaDevices.getUserMedia({
            audio: {
                echoCancellation: false,
                noiseSuppression: false,
                autoGainControl: false
            }
        });

        const mic = audioContext.createMediaStreamSource(stream);
        pitchNode = new AudioWorkletNode(audioContext, "pitch-processor");

        // Safari keep-alive
        const silent = audioContext.createGain();
        silent.gain.value = 0;

        mic.connect(pitchNode);
        pitchNode.connect(silent);
        silent.connect(audioContext.destination);

        let lastFreq = 0;
        let stable = 0;

        pitchNode.port.onmessage = e => {
            const { frequency, confidence, rms } = e.data;

            if (
                frequency > 0 &&
                rms > 0.004 &&
                confidence > 5e6 &&
                Math.abs(frequency - lastFreq) < 3
            ) {
                stable++;
                if (stable >= 3) {
                    currentPitch = frequency;
                    currentNote = frequencyToNote(frequency);
                }
            } else {
                stable = 0;
                currentNote = null;
            }

            lastFreq = frequency;
        };

        startButton.style.display = "none";
        requestAnimationFrame(draw);

    } catch (err) {
        alert("Startup error:\n" + err.message);
        console.error(err);
        startButton.textContent = "Error – Reload";
        startButton.disabled = false;
    }
}

function draw() {
    ctx.clearRect(0, 0, canvas.width, canvas.height);
    ctx.fillStyle = "#fff";
    ctx.font = "24px Arial";

    if (currentNote) {
        ctx.fillText(`Pitch: ${currentPitch.toFixed(1)} Hz`, 20, 50);
        ctx.fillText(`Note: ${currentNote}`, 20, 90);
    } else {
        ctx.fillText("Play a piano key…", 20, 60);
    }

    requestAnimationFrame(draw);
}

startButton.onclick = startAudio;
</script>
</body>
</html>
